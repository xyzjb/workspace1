{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiabo.zhou\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d1351909326e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mpar2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--datasetname\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasetname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pandas_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_cached_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from poseidon import poseidon\n",
    "import time\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import random\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from eapdataset import Dataset\n",
    "    \n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#print(par1)\n",
    "#par1='abcde0001'\n",
    "\n",
    "#%run train222.py --masterid $par1 --datasetname $datasetname  \n",
    "    \n",
    "# Model Tranining Sample\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "par1=os.environ.get(\"--masterid\")\n",
    "par2=os.environ.get(\"--datasetname\")\n",
    "#par2='power-forecast'\n",
    "\n",
    "dataset = Dataset.get_by_name(par2)\n",
    "df2=dataset.to_pandas_dataframe(use_cached_result=False)\n",
    "\n",
    "np.random.seed(40)\n",
    "data={}\n",
    "try:\n",
    "    data=df2.head(24962).fillna('1')\n",
    "\n",
    "except Exception as e:\n",
    "    logger.exception(\n",
    "            \"Get Hive Data Error: %s\", e)\n",
    "\n",
    "    \n",
    "train, test = train_test_split(data)\n",
    "\n",
    "# The predicted column is \"power\"\n",
    "train_x = train.drop([\"x_basic_forecast_time\",\"x_basic_time\",\"ec_nwp_time\",\"gfs_nwp_time\",\"power\",\"speed\"], axis=1)\n",
    "test_x = test.drop([\"x_basic_forecast_time\",\"x_basic_time\",\"ec_nwp_time\",\"gfs_nwp_time\",\"power\",\"speed\"], axis=1)\n",
    "train_y = train[[\"power\"]]\n",
    "test_y = test[[\"power\"]]\n",
    "    \n",
    "    \n",
    "# Set default values if no alpha is provided\n",
    "alpha = 0.5\n",
    "l1_ratio = 0.5\n",
    "\n",
    "\n",
    "\n",
    "# Useful for multiple runs (only doing one run in this sample notebook)    \n",
    "with mlflow.start_run() as run:\n",
    "    # Execute ElasticNet\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(train_x, train_y)\n",
    "        \n",
    "    #print(test_x)\n",
    "    # Evaluate Metrics\n",
    "    predicted_powers = lr.predict(test_x)\n",
    "    (rmse, mae, r2) = eval_metrics(test_y, predicted_powers)\n",
    "\n",
    "\n",
    "\n",
    "    # Log parameter, metrics, and model to MLflow\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
